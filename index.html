<!-- Abstract -->
<body>
  <div class="text" style="font-size:50px">
    Ditto: Disentangled Modeling for Multi-Task Text-to-Speech
  </div>
  <div class="text" style="font-size:20px">
    Anonymous Authors
  </div>
  <div class="text" style="font-size:10px">
    &nbsp;
  </div>
  <div class="text" style="font-size:40px">
    Abstract
  </div>
  <div class="text" style="font-size:15px">
    This paper introduces "Ditto," a novel deep-learning model for multi-task speech synthesis. Addressing the challenges of generalization, we employ a disentangled modeling for speech that separates content, style, and prosody. To this end, our multi-task TTS model utilizes a source-filter model for feature disentanglement and prompt-based auto-regressive prosody modeling. The proposed model excels in zero-shot synthesis, cross-lingual synthesis, and style transfer. Additionally, it handles these tasks with a unified approach, consolidating them within a single, versatile framework. Leveraging disentangled modeling, Ditto achieves robust generalization, requiring relatively less training data compared to data-driven approaches. Experimental results describe its superior zero-shot synthesis, even in cross-lingual scenarios, emphasizing enhanced speech intelligibility, speaker similarity, and prosody similarity.
  </div>
  <p style="text-align: center;">
    <img src="./ditto.png" alt="Overview" width="400">
  </p>
</body>
